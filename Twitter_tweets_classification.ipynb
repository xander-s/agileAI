{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xander-s/agileAI/blob/main/Twitter_tweets_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4HH1zze4Z8g",
        "outputId": "70d98510-83a0-43eb-d6bc-cba25133af21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.3.9-py3-none-any.whl (221 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "openai.api_key=userdata.get('API_KEY')\n",
        "\n",
        "def analyze_sentiment_with_openai(tweet):\n",
        "    prompt = f\"Classify the sentiment only within the given for the following tweet '{tweet}': as fear, helpless, disappointment, terror\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\":\"user\",\"content\":prompt+\"print the sentiment only\"\n",
        "            }\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    generated_sentiment = response.choices[0].message.content\n",
        "\n",
        "    return generated_sentiment[generated_sentiment.rfind(\" \")+1:]\n",
        "\n",
        "def categorize_priority():\n",
        "    category_prompt= f\"Categorize the priority of the '{tweet}' as high or medium or low and print the category only\"\n",
        "\n",
        "    category_response=openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\":\"user\",\n",
        "                \"content\":category_prompt\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    generated_category = category_response.choices[0].message.content\n",
        "\n",
        "    return generated_category\n",
        "\n",
        "def categorize_sentiment(sentiment):\n",
        "  if sentiment == 'fear' or sentiment == 'terror':\n",
        "    print('Thank you for contacting us. Stay calm, Our concerned team will be reaching out to you soon. Your safety is our priority and it is being taken care of. You are in the safe hands now. The help is on the way.')\n",
        "  elif sentiment == 'disappointment' or sentiment == 'helpless':\n",
        "    print('Thank you for contacting us. We regret for what had happened. We take care of your safety and we are working towards the safety of our community. Our team will be taking care of your concern. We assure you that the action will be taken on priority and we ensure that it will not happen again')\n",
        "\n",
        "\n",
        "tweets = [\n",
        "    \"My mobile phone was snatched by unknown members. Kindly help me to get my mobile\"\n",
        "]\n",
        "\n",
        "for tweet in tweets:\n",
        "  sentiment = analyze_sentiment_with_openai(tweets)\n",
        "  category = categorize_priority()\n",
        "  print(f'Tweet: \"{tweets}\"')\n",
        "  print(f'Sentiment: {sentiment}')\n",
        "  print(f'{category}')\n",
        "  categorize_sentiment(sentiment)\n",
        "  print('---')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM69J-vMkSW1",
        "outputId": "ef7154c4-078e-4b5a-d977-af3972e9bde1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: \"['My mobile phone was snatched by unknown members. Kindly help me to get my mobile']\"\n",
            "Sentiment: helpless\n",
            "high\n",
            "Thank you for contacting us. We regret for what had happened. We take care of your safety and we are working towards the safety of our community. Our team will be taking care of your concern. We assure you that the action will be taken on priority and we ensure that it will not happen again\n",
            "---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}